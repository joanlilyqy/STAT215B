\documentclass{article}

\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{\today}
\chead{Ying Qiao SID:21412301}
\rhead{Stat215B Sp13: Assignment 7}
\lfoot{}
\cfoot{\thepage}
\rfoot{}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{amssymb,amsmath}
\usepackage{bm}
\usepackage{hhline}

%% for inline R code: if the inline code is not correctly parsed, you will see a message
\newcommand{\rinline}[1]{SOMETHING WORNG WITH knitr}
%% begin.rcode setup, include=FALSE
% opts_chunk$set(fig.path='figure/latex-', cache.path='cache/latex-')
%% end.rcode


\begin{document}
\section*{Regression, Prediction and Shrinkage}
In this assignment, we will demonstrate the comparison of prediction
accuarcy among several linear predictors, i.e. ordinary least square
(OLS) predictors, pre-shrunk predictors as in Copas(1983) and shrinkage
predictor by cross-validation.

\subsubsection*{Simulation Setup}
\hspace{12 pt} 
To demonstrate the required statements about prediction mean square
error (PMSE) of the three predictors. We choose the simulation
parameters as shown in the table below.

%%  begin.rcode ass7-00,cache=TRUE,results="hide",message=FALSE,echo=FALSE
%%rm(list=ls())
%%require(MASS)
%%load('copas.Rdata')
%%  end.rcode

\begin{center}
%%\caption{Table 1}
\begin{tabular}{l|c|r} \hline
\texttt{Simulation Parameter} & \texttt{Symbol} & \texttt{Value}  \\ \hline
predictor dimension & $p$ & \rinline{p} \\ \hline
number of overall samples & $n$ & \rinline{n} \\
number of training samples & $n_{CS}$ & \rinline{n.cs} \\
number of test samples & $n_{VS}$ & \rinline{n.vs} \\ \hline
true intercept & $\alpha$ & \rinline{alpha} \\ 
true coefficients & $\bm{\beta}$ &  $\in$[\rinline{min(beta)}, \rinline{max(beta)}]\\ \hline
noise-signal-ratio & $\delta^2$ & \rinline{del2} \\
noise variance & $\sigma^2$ & \rinline{sig2} \\ \hline
simulation runs & $N$ & \rinline{N.rep} \\ \hline
cross-validation folds & $k$ & \rinline{k} \\ \hline
\end{tabular}
\end{center}

In order to show the strength of Copas(1983) method, we would like a
relatively large $p$ with a relatively small $n$. Also, the error
variance $\sigma^2$ should be comparable to $\bm{\beta^T}V\bm{\beta}$
with non-zero noise-signal-ratio $\delta^2$. So, as suggested by the
Breiman\&Friedman(1997) paper design, we set our simulation parameters
as above. The true linear model parameters, $\alpha, \bm{\beta}$ ,are not critical, so we
just made some simple choices. Moreover, for strong hypothesis testing
power, we have fairly large repetition runs, $N$, of simulations.


As for the data statistics, for each run, the predictor variables are
generated according to a normal distribution with zero mean and
covariance matrix $\bm{\Xi}$,
\begin{displaymath}
\begin{split}
\bm{x} &\sim  \mathcal{\bm{N}}(\bm{0}, \bm{\Xi})\\
\bm{\Xi} &= [V_{ij}]_{p\times p} , \hspace{12 pt} V_{ij} = r^{|i-j|},
\hspace{12 pt} r \sim \mathcal{U}[0,1]
\end{split}
\end{displaymath}
Also, the model matrix $\bm{X}$ is column centered for simplicity
(without loss of generality), and we have $\bm{V}=\frac{1}{n}\bm{X^TX}$. 
Meanwhile, for both \textit{construction sample}(CS) and
\textit{validation sample}(VS), the data sample vector
$\bm{y}$ are generated independently w.r.t each element,
\begin{displaymath}
\begin{split}
y &= \alpha + \bm{\beta^Tx} + \epsilon\\
\epsilon &\sim \mathcal{N}(0, \sigma^2)
\end{split}
\end{displaymath}
So, we can see that the randomness in my simulation comes from three
sources: first, the randomness between each run (rep. of dim=$N$); second, the
randomness in the data noise ($\epsilon$ of dim=$n$); and finally, the
randomness in the predictive factors ($x$ of dim=$p$).


Additionally, to verify the correctness of my implementation, we would
like to check if our estimates, $\hat{\sigma}^2$, are unbiased according to
a one-sample $t$-test with target $\mu_0=\sigma^2$.
\begin{displaymath}
\begin{split}
\hat{\sigma}^2 &= \frac{1}{\nu}\sum_{i=1}^{n_{CS}} (y_i - \hat{y}_i^{OLS})^2 \\
\nu &= n_{CS} - (p+1)
\end{split}
\end{displaymath}
And the two-sided $t$-test results in a p-value of
\rinline{t.test(sig2hat, mu=sig2)$p.value}, 
which confirms that our estimates are unbiased.

Moreover, we also want to check if the $\bm{V}$ (as defined in
Copas(1983)) is close to the true covariance matrix $\bm{\Xi}$ in
terms of the Frobenius norm. 
\begin{displaymath}
\begin{split}
|\bm{V}||_F &= \sum_{i=1}^p \sum_{j=1}^p |V_{ij}|^2 \\
||\bm{\Xi}||_F &= \sum_{i=1}^p \sum_{j=1}^p |\Xi_{ij}|^2 \\
\end{split}
\end{displaymath}
We conduct a two-sample $t$-test on the $N$ samples of matrix norms
and get the p-value of 
\rinline{t.test(Vnorm, covXnorm)$p.value},
which confirms that we can trust the $\bm{V}$ approximation.


Now, we are safe to proceed and check the hypothesis in the statements.


\subsubsection*{Statement 1: Copas vs. OLS}
\hspace{12 pt}  We want to evaluate


\hspace{12 pt} \textit{H0: the PMSE of Copas pre-shrunk predictor is
  the same as that of OLS} \newline
\vspace{2 pt}
\hspace{24 pt} \textit{HA: the PMSE of Copas pre-shrunk predictor is
  lower than that of OLS} \newline


We have the predictors with OLS parameter estimates, $\hat{\alpha},
\bm{\hat{\beta}}$, for CS data samples,
\begin{displaymath}
\begin{split}
\hat{y}^{OLS} &= \hat{\alpha} + \bm{\hat{\beta}^Tx} \\
\hat{y}^{Copas} &= \hat{\alpha} + \hat{K}\bm{\hat{\beta}^Tx},
\hspace{12 pt} \hat{K} = 1 - \frac{(p-2)\hat{\sigma}^2\nu}{n_{CS}(\nu+2)\bm{\hat{\beta}^TV\hat{\beta}}}
\end{split}
\end{displaymath}
and then conduct a one-sided two-sample $t$-test on the PMSE values obtained
from $N$ runs on the VS samples,
\begin{displaymath}
PMSE = \frac{1}{n_{VS}} \sum_{i=1}^{n_{VS}} (y_i - \hat{y}_i)^2
\end{displaymath}
the test gives a p-value of 
\rinline{t.test(PMSE$copas, PMSE$ols, alter = 'less')$p.value}
which rejects the null hypothesis and shows that PMSE of Copas
pre-shrunk predictor is lower than that of OLS.


%%  begin.rcode ass7-1,cache=TRUE,echo=FALSE,results="markup",dev='pdf',fig.height=6,fig.width=7,fig.align="center",fig.cap="PMSE Copas vs. OLS"
%%PMSE <- data.frame(PMSE)
%%boxplot(PMSE$copas, PMSE$ols, names=names(PMSE)[c(2,1)])
%%  end.rcode



\subsubsection*{Statement 2: Copas vs. Cross-validation}
\hspace{12 pt}  We want to evaluate


\hspace{12 pt} \textit{H0: the PMSE of Copas pre-shrunk predictor is
  the same as that of shrinkage estimated from cross-validation} \newline
\vspace{2 pt}
\hspace{24 pt} \textit{HA: the PMSE of Copas pre-shrunk predictor is
  lower than that of shrinkage estimated from cross-validation} \newline


We have the predictors with OLS parameter estimates, $\hat{\alpha},
\bm{\hat{\beta}}$, for CS data samples,
\begin{displaymath}
\begin{split}
\hat{y}^{Copas} &= \hat{\alpha} + \hat{K}\bm{\hat{\beta}^Tx},
\hspace{12 pt} \hat{K} = 1 -\frac{(p-2)\hat{\sigma}^2\nu}{n_{CS}(\nu+2)\bm{\hat{\beta}^TV\hat{\beta}}}\\
\hat{y}^{CV} &= \hat{\alpha} + \tilde{K}\bm{\hat{\beta}^Tx},
\hspace{12 pt} \tilde{K} = K^{CV}_{l^*}, \hspace{12 pt} l^* = min_lPMSE^{CV}_l\\
&\hspace{64 pt} K^{CV}_l = \frac{Cov(y^{CV:VS_l},  \hat{y}^{CV:VS_l})}{Var(\hat{y}^{CV:VS_l})},
\hspace{12 pt} \hat{y}^{CV:VS_l}_i = \hat{\alpha}^{CV:CS_l} + (\bm{\hat{\beta}}^{CV:CS_l})^T\bm{x}_i^{CV:VS_l}\\
&\hspace{64 pt} PMSE^{CV}_l = \frac{1}{n_{CS}/k} \sum_{i=1}^{n_{CS}/k} (y^{CV:VS_l}_i - \hat{y}^{CV:VS_l}_i)^2\\
\end{split}
\end{displaymath}
and then conduct a one-sided two-sample $t$-test on the PMSE values obtained
from $N$ runs on the VS samples, the test gives a p-value of 
\rinline{t.test(PMSE$copas, PMSE$crosval, alter = 'less')$p.value}
which rejects the null hypothesis and shows that PMSE of Copas
pre-shrunk predictor is lower than that of shrinkage estimated from cross-validation.


%%  begin.rcode ass7-2,cache=TRUE,echo=FALSE,results="markup",dev='pdf',fig.height=6,fig.width=7,fig.align="center",fig.cap="PMSE Copas vs. Cross-validation"
%%boxplot(PMSE$copas, PMSE$crosval, names=names(PMSE)[c(2,3)])
%%  end.rcode



\subsubsection*{Statement 3: Copas vs. Cross-validation | non-normal noise}
\hspace{12 pt}  We want to evaluate


\hspace{12 pt} \textit{H0: the PMSE of Copas pre-shrunk predictor is
  the same as that of shrinkage estimated from cross-validation under
  non-normal noise} \newline
\vspace{2 pt}
\hspace{24 pt} \textit{HA: the PMSE of Copas pre-shrunk predictor is
  larger than that of shrinkage estimated from cross-validation under
  non-normal noise} \newline


We have the same predictors as in statement 2, but here 





and then conduct a one-sided two-sample $t$-test on the PMSE values obtained
from $N$ runs on the VS samples, the test gives a p-value of 
%\rinline{t.test(PMSE$copas, PMSE$crosval, alter = 'greater')$p.value}
which rejects the null hypothesis and shows that PMSE of Copas
pre-shrunk predictor is larger than that of shrinkage estimated from cross-validation.


%%  begin.rcode ass7-3,cache=TRUE,echo=FALSE,results="markup",dev='pdf',fig.height=6,fig.width=7,fig.align="center",fig.cap="PMSE Copas vs. Cross-validation given non-normal noise"
%%boxplot(PMSE$copas, PMSE$crosval, names=names(PMSE)[c(2,3)])
%%  end.rcode



\end{document}
